{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOdSK8Bj4w7E1SUw8AwWQ0r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hario27/PositionChecker/blob/master/keras1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifgGxo-PRcgG",
        "outputId": "ffcb377f-2e24-4ccb-c8be-c60ce6a77912"
      },
      "source": [
        "!pip install hyperas"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/04/34/87ad6ffb42df9c1fa9c4c906f65813d42ad70d68c66af4ffff048c228cd4/hyperas-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from hyperas) (2.4.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from hyperas) (5.1.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas) (5.3.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas) (5.0.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas) (7.6.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->hyperas) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->hyperas) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->hyperas) (1.19.5)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.7/dist-packages (from nbformat->hyperas) (5.0.5)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->hyperas) (4.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (2.11.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (2.6.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (3.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (3.11.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (2.5)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->hyperas) (5.3.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->hyperas) (0.9.2)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->hyperas) (22.0.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->hyperas) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->hyperas) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt->hyperas) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->jupyter-console->jupyter->hyperas) (2.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.2.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (54.1.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.7.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n",
            "Installing collected packages: hyperas\n",
            "Successfully installed hyperas-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UTYBiQ7e67-y",
        "outputId": "6639e9b3-ed57-41ce-8876-3e7435250c23"
      },
      "source": [
        "!pip install tsfresh"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tsfresh\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/7f/53e845c3e19078d15e228db642ad06d5a91207a66115cb4f30a2eca28f17/tsfresh-0.18.0-py2.py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 5.9MB/s \n",
            "\u001b[?25hCollecting distributed>=2.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/c1/91808d0295d2b22fafa73e55886c16646614993bc74668714af8c651c896/distributed-2021.3.1-py3-none-any.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 18.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (1.19.5)\n",
            "Collecting matrixprofile>=1.1.10<2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/c3/43d282f0e5299f977b62e53e4dde22ddb14c90877af5b62af225fa783d8e/matrixprofile-1.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (4.41.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (0.5.1)\n",
            "Requirement already satisfied: dask[dataframe]>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (2.12.0)\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (1.4.1)\n",
            "Collecting stumpy>=1.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/da/8d372a1af518930ecb3ad9acc627115450149b613ba1b9b51b4d3721218e/stumpy-1.8.0-py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (1.0.2)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (54.1.2)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (0.11.1)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (5.1.1)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (2.3.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (1.7.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (3.13)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (2.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->tsfresh) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->tsfresh) (2.8.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from matrixprofile>=1.1.10<2.0.0->tsfresh) (3.2.2)\n",
            "Collecting protobuf==3.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/14/f5c294f1e36a031f165128c25feba93b3116f15a74398d0b2747ed75744f/protobuf-3.11.2-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.0->tsfresh) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.4.1->tsfresh) (1.15.0)\n",
            "Collecting fsspec>=0.6.0; extra == \"dataframe\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 54.2MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10; extra == \"dataframe\"\n",
            "  Downloading https://files.pythonhosted.org/packages/44/e1/68dbe731c9c067655bff1eca5b7d40c20ca4b23fd5ec9f3d17e201a6f36b/partd-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->tsfresh) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->tsfresh) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->tsfresh) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->tsfresh) (1.24.3)\n",
            "Requirement already satisfied: numba>=0.48 in /usr/local/lib/python3.7/dist-packages (from stumpy>=1.7.2->tsfresh) (0.51.2)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.11.0->tsfresh) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->matrixprofile>=1.1.10<2.0.0->tsfresh) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->matrixprofile>=1.1.10<2.0.0->tsfresh) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->matrixprofile>=1.1.10<2.0.0->tsfresh) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]>=2.9.0->tsfresh) (3.7.2)\n",
            "Collecting locket\n",
            "  Downloading https://files.pythonhosted.org/packages/50/b8/e789e45b9b9c2db75e9d9e6ceb022c8d1d7e49b2c085ce8c05600f90a96b/locket-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48->stumpy>=1.7.2->tsfresh) (0.34.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]>=2.9.0->tsfresh) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]>=2.9.0->tsfresh) (3.4.1)\n",
            "\u001b[31mERROR: googleapis-common-protos 1.53.0 has requirement protobuf>=3.12.0, but you'll have protobuf 3.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-core 1.26.1 has requirement protobuf>=3.12.0, but you'll have protobuf 3.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: distributed 2021.3.1 has requirement dask>=2021.03.0, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: stumpy 1.8.0 has requirement scipy>=1.5, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cloudpickle, distributed, protobuf, matrixprofile, stumpy, tsfresh, fsspec, locket, partd\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "Successfully installed cloudpickle-1.6.0 distributed-2021.3.1 fsspec-0.8.7 locket-0.2.1 matrixprofile-1.1.10 partd-1.1.0 protobuf-3.11.2 stumpy-1.8.0 tsfresh-0.18.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbR9UNf48ZyS",
        "outputId": "7ce212a8-223a-40c8-e353-61aaa470a258"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#from tsfresh import extract_features\n",
        "#from tsfresh import select_features\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.feature_selection import SelectPercentile\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_selection import RFECV, RFE\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import Lasso, LassoCV\n",
        "\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiflpSj7R73_"
      },
      "source": [
        "def data():\n",
        "  # CSV読み込み\n",
        "  print(\"CSV読み込み==============================================================================\")\n",
        "  df_origin = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/feature_data_test.csv\")\n",
        "\n",
        "  # 特徴量作成\n",
        "  \"\"\"\n",
        "  print(\"\\n特徴量作成==============================================================================\")\n",
        "  temp = pd.DataFrame(df[\"Close\"], columns=['Close'], dtype='float')\n",
        "  serial_num = pd.RangeIndex(start=0, stop=len(df.index) , step=1)\n",
        "  temp[\"id\"] = serial_num\n",
        "  extracted_features = extract_features(temp, column_id='id')\n",
        "  print(extracted_features)\n",
        "  df = pd.concat([df, extracted_features], axis=1)\n",
        "  df = df.dropna(axis=1)\n",
        "  \"\"\"\n",
        "\n",
        "  # データ分割\n",
        "  print(\"\\n訓練テストデータ分割==============================================================================\")\n",
        "  df = df_origin[0:len(df_origin) - 30]\n",
        "  print(df)\n",
        "  df = df[-5000:]\n",
        "  df.reset_index(inplace=True)\n",
        "  X = df.drop([\"datetime\", \"Target(30)\", \"Open\", \"Close\", \"High\", \"Low\", \"index\", \"Volume\", \"hour\", \"dayweek\"], axis=1)\n",
        "  y = df[f\"Target({str(30)})\"]\n",
        "  print(X)\n",
        "\n",
        "  print(\"\\n検証データ分割==============================================================================\")\n",
        "  df1 = df_origin[-30:]\n",
        "  df1.reset_index(inplace=True)\n",
        "  X1 = df1.drop([\"datetime\", \"Target(30)\", \"Open\", \"Close\", \"High\", \"Low\", \"index\", \"Volume\", \"hour\", \"dayweek\"], axis=1)\n",
        "  print(X1)\n",
        "  \n",
        "  # 次元削減\n",
        "  \"\"\"\n",
        "  print(\"\\n次元削減==============================================================================\")\n",
        "  X_selected = select_features(X, y)\n",
        "  X_selected[\"hour\"] = hour\n",
        "  X_selected[\"dayweek\"] = dayweek\n",
        "  print(X_selected)\n",
        "  \"\"\"\n",
        "\n",
        "  # 次元圧縮\n",
        "  \"\"\"\n",
        "  print(\"\\n次元圧縮==============================================================================\")\n",
        "  n_components = int(X_selected.shape[1] * 0.8)\n",
        "  pca = PCA(n_components=n_components)\n",
        "  pca.fit(X_selected)\n",
        "  X_selected_pca = pca.transform(X_selected)\n",
        "  print(X_selected_pca.shape)\n",
        "  print(X_selected_pca)\n",
        "  \"\"\"\n",
        "\n",
        "  # ホールドアウト分割\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
        "\n",
        "  \"\"\"\n",
        "  print(\"SelectPercentile\")\n",
        "  select = SelectPercentile(percentile=5)\n",
        "  print(\"FIT\")\n",
        "  select.fit(x_train, y_train)\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  criterion=\"gini\"\n",
        "  numFeatures = 6\n",
        "  nEstimators = 65\n",
        "  predWindow = 1\n",
        "  oobScore = True\n",
        "  randomForest1 = RandomForestClassifier(\n",
        "      n_estimators = nEstimators,\n",
        "      max_features = numFeatures,\n",
        "      bootstrap = True,\n",
        "      oob_score = oobScore,\n",
        "      verbose = 0,\n",
        "      criterion = criterion,\n",
        "      n_jobs = -1,\n",
        "      random_state = 42\n",
        "  )\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  print(\"SelectFromModel\")\n",
        "  select = SelectFromModel(estimator=randomForest1, threshold=0.001)\n",
        "  print(\"FIT\")\n",
        "  select.fit(x_train, y_train)\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"RFE\")\n",
        "\t#select = RFECV(lgb.LGBMClassifier(objective=\"binary\", metric=\"binary_logloss\", random_state=42), step=1, scoring=\"accuracy\", verbose=1)\n",
        "  #select = RFE(lgb.LGBMClassifier(objective=\"binary\", logloss=\"rmse\", random_state=42), n_features_to_select=80, step=0.5, verbose=1)\n",
        "\t#clf = Lasso(alpha=0.1, max_iter=1000)\n",
        "  clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "  select = RFE(estimator=clf, n_features_to_select=40, verbose=1)\n",
        "  print(\"FIT\")\n",
        "  select.fit(x_train, y_train) \n",
        "  display(x_train.columns.values[select.support_])\n",
        "\n",
        "  print(x_train.shape)\n",
        "  x_train = select.transform(x_train)\n",
        "  x_test = select.transform(x_test)\n",
        "  X1_selected_pca = select.transform(X1)\n",
        "  print(x_train.shape)\n",
        "  print(X1_selected_pca.shape)\n",
        "\n",
        "  \"\"\"\n",
        "  print(\"aaaa\")\n",
        "  print(x_train)\n",
        "  x_train = x_train[['slowd17', 'slowd20', 'slowd71', 'slowd72', 'slowd88', 'slowk91',\n",
        "       'slowk100', 'slowd104', 'slowd123', 'slowd141', 'PPO149', 'PPO181',\n",
        "       'PPO195', 'slowk197', 'slowd200', 'PPO203', 'slowd203', 'slowd210',\n",
        "       'detrendedClose', 'ADX25', 'WR65', 'WR75', 'ADX135',\n",
        "       'lowerband145', 'CORREL145', 'CORREL155', 'kairi165', 'CORREL165',\n",
        "       'upperband175', 'EMA185', 'lowerband195', 'EMA195', 'WR195',\n",
        "       'PROC205', 'ADX215', 'CCI215', 'PROC215', 'TYPPRICE', 'WCLPRICE',\n",
        "       'AD']]\n",
        "  x_test = x_test[['slowd17', 'slowd20', 'slowd71', 'slowd72', 'slowd88', 'slowk91',\n",
        "       'slowk100', 'slowd104', 'slowd123', 'slowd141', 'PPO149', 'PPO181',\n",
        "       'PPO195', 'slowk197', 'slowd200', 'PPO203', 'slowd203', 'slowd210',\n",
        "       'detrendedClose', 'ADX25', 'WR65', 'WR75', 'ADX135',\n",
        "       'lowerband145', 'CORREL145', 'CORREL155', 'kairi165', 'CORREL165',\n",
        "       'upperband175', 'EMA185', 'lowerband195', 'EMA195', 'WR195',\n",
        "       'PROC205', 'ADX215', 'CCI215', 'PROC215', 'TYPPRICE', 'WCLPRICE',\n",
        "       'AD']]\n",
        "\n",
        "  X1_selected_pca = X1\n",
        "  X1_selected_pca = X1_selected_pca[['slowd17', 'slowd20', 'slowd71', 'slowd72', 'slowd88', 'slowk91',\n",
        "       'slowk100', 'slowd104', 'slowd123', 'slowd141', 'PPO149', 'PPO181',\n",
        "       'PPO195', 'slowk197', 'slowd200', 'PPO203', 'slowd203', 'slowd210',\n",
        "       'detrendedClose', 'ADX25', 'WR65', 'WR75', 'ADX135',\n",
        "       'lowerband145', 'CORREL145', 'CORREL155', 'kairi165', 'CORREL165',\n",
        "       'upperband175', 'EMA185', 'lowerband195', 'EMA195', 'WR195',\n",
        "       'PROC205', 'ADX215', 'CCI215', 'PROC215', 'TYPPRICE', 'WCLPRICE',\n",
        "       'AD']]\n",
        "  \"\"\"\n",
        "\n",
        "  # 正規化\n",
        "  sc = StandardScaler()\n",
        "  sc.fit(x_train)\n",
        "  x_train = sc.transform(x_train)\n",
        "  x_test = sc.transform(x_test)\n",
        "  x_valid = sc.transform(X1_selected_pca)\n",
        "\n",
        "  display(x_test.shape)\n",
        "\n",
        "  \"\"\"\n",
        "  poly = PolynomialFeatures(degree=2).fit(x_train)\n",
        "  x_train = poly.transform(x_train)\n",
        "  x_test = poly.transform(x_test)\n",
        "  \"\"\"\n",
        "\n",
        "  x_train = np.asarray(x_train).astype(\"float64\")\n",
        "  x_test = np.asarray(x_test).astype(\"float64\")\n",
        "  y_train = np.asarray(y_train).astype(\"float32\")\n",
        "  y_test = np.asarray(y_test).astype(\"float32\")\n",
        "  x_valid = np.asarray(x_valid).astype(\"float32\")\n",
        "\n",
        "  return x_train, y_train, x_test, y_test, x_valid"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_GUdJdhQNiu"
      },
      "source": [
        "def model(x_train, y_train, x_test, y_test, x_valid):\n",
        "  model = Sequential()\n",
        "  model.add(Dense({{choice([32, 64, 128, 256, 512, 1024])}}, activation={{choice([\"relu\", \"tanh\"])}}, input_shape=(x_train.shape[1],)))\n",
        "  model.add(Dropout({{uniform(0, 1)}}))\n",
        "  model.add(Dense({{choice([32, 64, 128, 256, 512, 1024])}}, activation={{choice([\"relu\", \"tanh\"])}}))\n",
        "  model.add(Dropout({{uniform(0, 1)}}))\n",
        "  model.add(Dense(1, activation=\"sigmoid\"))\n",
        "  sgd = SGD(lr=0.01, momentum=0.9, decay=1e-4, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss=\"mse\", metrics=[\"acc\"])\n",
        "  callbacks_list = [EarlyStopping(monitor=\"val_loss\", patience=10)]\n",
        "  history = model.fit(x_train, y_train, epochs=1000, batch_size={{choice([32, 64, 126, 256, 512])}}, validation_data=(x_test, y_test), verbose=0, callbacks=callbacks_list)\n",
        "\n",
        "  val_loss, val_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Test accuracy:', val_acc)\n",
        "  print('Test loss:', val_loss)\n",
        "\n",
        "  \"\"\"\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict[\"loss\"]\n",
        "  val_loss_values = history_dict[\"val_loss\"]\n",
        "\n",
        "  epochs = range(1, len(loss_values) + 1)\n",
        "  \n",
        "  plt.clf()\n",
        "  # \"bo\"は\"blue dot(青のドット)を意味する\n",
        "  plt.plot(epochs, loss_values, \"b\", label=\"Traning loss\")\n",
        "  # \"b\"はsolod blue line(青の実線)を意味する\n",
        "  plt.plot(epochs, val_loss_values, \"r\", label=\"Validation loss\")\n",
        "  plt.title(\"Traning and validation loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \"\"\"\n",
        "\n",
        "  return {'loss': -val_acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o7i_tBRQ743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd257699-a6f2-4a9a-cdd5-453e5d984e91"
      },
      "source": [
        "best_run, best_model = optim.minimize(model=model,\n",
        "                                          data=data,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          max_evals=1000,\n",
        "                                          notebook_name=os.path.join('drive','My Drive','Colab Notebooks','keras1'),\n",
        "                                          trials=Trials())\n",
        "\n",
        "print(best_model.summary())\n",
        "print(best_run)\n",
        "\n",
        "_, _, x_test, y_test, x_valid = data()\n",
        "print(\"tesuto\")\n",
        "print(x_valid)\n",
        "val_loss, val_acc = best_model.evaluate(x_test, y_test)\n",
        "print(\"val_loss: \", val_loss)\n",
        "print(\"val_acc: \", val_acc)\n",
        "y_pred_proba = best_model.predict(x_valid)\n",
        "y_pred = np.where(y_pred_proba > 0.5, 1, 0)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    import pandas as pd\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import drive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.decomposition import PCA\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.feature_selection import SelectPercentile\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.feature_selection import SelectFromModel\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.feature_selection import RFECV, RFE\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import GridSearchCV, cross_val_score\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.ensemble import RandomForestClassifier\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import lightgbm as lgb\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import xgboost as xgb\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.linear_model import Lasso, LassoCV\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import keras\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Activation, Dropout\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.callbacks import EarlyStopping\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.optimizers import SGD\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dense': hp.choice('Dense', [32, 64, 128, 256, 512, 1024]),\n",
            "        'activation': hp.choice('activation', [\"relu\", \"tanh\"]),\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Dense_1': hp.choice('Dense_1', [32, 64, 128, 256, 512, 1024]),\n",
            "        'activation_1': hp.choice('activation_1', [\"relu\", \"tanh\"]),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
            "        'batch_size': hp.choice('batch_size', [32, 64, 126, 256, 512]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "   1: \n",
            "   2: # CSV読み込み\n",
            "   3: print(\"CSV読み込み==============================================================================\")\n",
            "   4: df_origin = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/feature_data_test.csv\")\n",
            "   5: \n",
            "   6: # 特徴量作成\n",
            "   7: \"\"\"\n",
            "   8: print(\"\\n特徴量作成==============================================================================\")\n",
            "   9: temp = pd.DataFrame(df[\"Close\"], columns=['Close'], dtype='float')\n",
            "  10: serial_num = pd.RangeIndex(start=0, stop=len(df.index) , step=1)\n",
            "  11: temp[\"id\"] = serial_num\n",
            "  12: extracted_features = extract_features(temp, column_id='id')\n",
            "  13: print(extracted_features)\n",
            "  14: df = pd.concat([df, extracted_features], axis=1)\n",
            "  15: df = df.dropna(axis=1)\n",
            "  16: \"\"\"\n",
            "  17: \n",
            "  18: # データ分割\n",
            "  19: print(\"\\n訓練テストデータ分割==============================================================================\")\n",
            "  20: df = df_origin[0:len(df_origin) - 30]\n",
            "  21: print(df)\n",
            "  22: df = df[-5000:]\n",
            "  23: df.reset_index(inplace=True)\n",
            "  24: X = df.drop([\"datetime\", \"Target(30)\", \"Open\", \"Close\", \"High\", \"Low\", \"index\", \"Volume\", \"hour\", \"dayweek\"], axis=1)\n",
            "  25: y = df[f\"Target({str(30)})\"]\n",
            "  26: print(X)\n",
            "  27: \n",
            "  28: print(\"\\n検証データ分割==============================================================================\")\n",
            "  29: df1 = df_origin[-30:]\n",
            "  30: df1.reset_index(inplace=True)\n",
            "  31: X1 = df1.drop([\"datetime\", \"Target(30)\", \"Open\", \"Close\", \"High\", \"Low\", \"index\", \"Volume\", \"hour\", \"dayweek\"], axis=1)\n",
            "  32: print(X1)\n",
            "  33: \n",
            "  34: # 次元削減\n",
            "  35: \"\"\"\n",
            "  36: print(\"\\n次元削減==============================================================================\")\n",
            "  37: X_selected = select_features(X, y)\n",
            "  38: X_selected[\"hour\"] = hour\n",
            "  39: X_selected[\"dayweek\"] = dayweek\n",
            "  40: print(X_selected)\n",
            "  41: \"\"\"\n",
            "  42: \n",
            "  43: # 次元圧縮\n",
            "  44: \"\"\"\n",
            "  45: print(\"\\n次元圧縮==============================================================================\")\n",
            "  46: n_components = int(X_selected.shape[1] * 0.8)\n",
            "  47: pca = PCA(n_components=n_components)\n",
            "  48: pca.fit(X_selected)\n",
            "  49: X_selected_pca = pca.transform(X_selected)\n",
            "  50: print(X_selected_pca.shape)\n",
            "  51: print(X_selected_pca)\n",
            "  52: \"\"\"\n",
            "  53: \n",
            "  54: # ホールドアウト分割\n",
            "  55: x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
            "  56: \n",
            "  57: \"\"\"\n",
            "  58: print(\"SelectPercentile\")\n",
            "  59: select = SelectPercentile(percentile=5)\n",
            "  60: print(\"FIT\")\n",
            "  61: select.fit(x_train, y_train)\n",
            "  62: \"\"\"\n",
            "  63: \n",
            "  64: \"\"\"\n",
            "  65: criterion=\"gini\"\n",
            "  66: numFeatures = 6\n",
            "  67: nEstimators = 65\n",
            "  68: predWindow = 1\n",
            "  69: oobScore = True\n",
            "  70: randomForest1 = RandomForestClassifier(\n",
            "  71:     n_estimators = nEstimators,\n",
            "  72:     max_features = numFeatures,\n",
            "  73:     bootstrap = True,\n",
            "  74:     oob_score = oobScore,\n",
            "  75:     verbose = 0,\n",
            "  76:     criterion = criterion,\n",
            "  77:     n_jobs = -1,\n",
            "  78:     random_state = 42\n",
            "  79: )\n",
            "  80: \"\"\"\n",
            "  81: \n",
            "  82: \"\"\"\n",
            "  83: print(\"SelectFromModel\")\n",
            "  84: select = SelectFromModel(estimator=randomForest1, threshold=0.001)\n",
            "  85: print(\"FIT\")\n",
            "  86: select.fit(x_train, y_train)\n",
            "  87: \"\"\"\n",
            "  88: \n",
            "  89: print(\"RFE\")\n",
            "  90: select = RFECV(lgb.LGBMClassifier(objective=\"binary\", metric=\"binary_logloss\", random_state=42), step=1, scoring=\"accuracy\", verbose=1)\n",
            "  91: #select = RFE(lgb.LGBMClassifier(objective=\"binary\", logloss=\"rmse\", random_state=42), n_features_to_select=80, step=0.5, verbose=1)\n",
            "  92: clf = Lasso(alpha=0.1, max_iter=1000)\n",
            "  93: clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
            "  94: select = RFE(estimator=clf, n_features_to_select=40, verbose=1)\n",
            "  95: print(\"FIT\")\n",
            "  96: select.fit(x_train, y_train) \n",
            "  97: display(x_train.columns.values[select.support_])\n",
            "  98: \n",
            "  99: print(x_train.shape)\n",
            " 100: x_train = select.transform(x_train)\n",
            " 101: x_test = select.transform(x_test)\n",
            " 102: X1_selected_pca = select.transform(X1)\n",
            " 103: print(x_train.shape)\n",
            " 104: print(X1_selected_pca.shape)\n",
            " 105: \n",
            " 106: \"\"\"\n",
            " 107: print(\"aaaa\")\n",
            " 108: print(x_train)\n",
            " 109: x_train = x_train[['slowd17', 'slowd20', 'slowd71', 'slowd72', 'slowd88', 'slowk91',\n",
            " 110:      'slowk100', 'slowd104', 'slowd123', 'slowd141', 'PPO149', 'PPO181',\n",
            " 111:      'PPO195', 'slowk197', 'slowd200', 'PPO203', 'slowd203', 'slowd210',\n",
            " 112:      'detrendedClose', 'ADX25', 'WR65', 'WR75', 'ADX135',\n",
            " 113:      'lowerband145', 'CORREL145', 'CORREL155', 'kairi165', 'CORREL165',\n",
            " 114:      'upperband175', 'EMA185', 'lowerband195', 'EMA195', 'WR195',\n",
            " 115:      'PROC205', 'ADX215', 'CCI215', 'PROC215', 'TYPPRICE', 'WCLPRICE',\n",
            " 116:      'AD']]\n",
            " 117: x_test = x_test[['slowd17', 'slowd20', 'slowd71', 'slowd72', 'slowd88', 'slowk91',\n",
            " 118:      'slowk100', 'slowd104', 'slowd123', 'slowd141', 'PPO149', 'PPO181',\n",
            " 119:      'PPO195', 'slowk197', 'slowd200', 'PPO203', 'slowd203', 'slowd210',\n",
            " 120:      'detrendedClose', 'ADX25', 'WR65', 'WR75', 'ADX135',\n",
            " 121:      'lowerband145', 'CORREL145', 'CORREL155', 'kairi165', 'CORREL165',\n",
            " 122:      'upperband175', 'EMA185', 'lowerband195', 'EMA195', 'WR195',\n",
            " 123:      'PROC205', 'ADX215', 'CCI215', 'PROC215', 'TYPPRICE', 'WCLPRICE',\n",
            " 124:      'AD']]\n",
            " 125: \n",
            " 126: X1_selected_pca = X1\n",
            " 127: X1_selected_pca = X1_selected_pca[['slowd17', 'slowd20', 'slowd71', 'slowd72', 'slowd88', 'slowk91',\n",
            " 128:      'slowk100', 'slowd104', 'slowd123', 'slowd141', 'PPO149', 'PPO181',\n",
            " 129:      'PPO195', 'slowk197', 'slowd200', 'PPO203', 'slowd203', 'slowd210',\n",
            " 130:      'detrendedClose', 'ADX25', 'WR65', 'WR75', 'ADX135',\n",
            " 131:      'lowerband145', 'CORREL145', 'CORREL155', 'kairi165', 'CORREL165',\n",
            " 132:      'upperband175', 'EMA185', 'lowerband195', 'EMA195', 'WR195',\n",
            " 133:      'PROC205', 'ADX215', 'CCI215', 'PROC215', 'TYPPRICE', 'WCLPRICE',\n",
            " 134:      'AD']]\n",
            " 135: \"\"\"\n",
            " 136: \n",
            " 137: # 正規化\n",
            " 138: sc = StandardScaler()\n",
            " 139: sc.fit(x_train)\n",
            " 140: x_train = sc.transform(x_train)\n",
            " 141: x_test = sc.transform(x_test)\n",
            " 142: x_valid = sc.transform(X1_selected_pca)\n",
            " 143: \n",
            " 144: display(x_test.shape)\n",
            " 145: \n",
            " 146: \"\"\"\n",
            " 147: poly = PolynomialFeatures(degree=2).fit(x_train)\n",
            " 148: x_train = poly.transform(x_train)\n",
            " 149: x_test = poly.transform(x_test)\n",
            " 150: \"\"\"\n",
            " 151: \n",
            " 152: x_train = np.asarray(x_train).astype(\"float64\")\n",
            " 153: x_test = np.asarray(x_test).astype(\"float64\")\n",
            " 154: y_train = np.asarray(y_train).astype(\"float32\")\n",
            " 155: y_test = np.asarray(y_test).astype(\"float32\")\n",
            " 156: x_valid = np.asarray(x_valid).astype(\"float32\")\n",
            " 157: \n",
            " 158: \n",
            " 159: \n",
            " 160: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:   model = Sequential()\n",
            "   4:   model.add(Dense(space['Dense'], activation=space['activation'], input_shape=(x_train.shape[1],)))\n",
            "   5:   model.add(Dropout(space['Dropout']))\n",
            "   6:   model.add(Dense(space['Dense_1'], activation=space['activation_1']))\n",
            "   7:   model.add(Dropout(space['Dropout_1']))\n",
            "   8:   model.add(Dense(1, activation=\"sigmoid\"))\n",
            "   9:   sgd = SGD(lr=0.01, momentum=0.9, decay=1e-4, nesterov=True)\n",
            "  10:   model.compile(optimizer=sgd, loss=\"mse\", metrics=[\"acc\"])\n",
            "  11:   callbacks_list = [EarlyStopping(monitor=\"val_loss\", patience=10)]\n",
            "  12:   history = model.fit(x_train, y_train, epochs=1000, batch_size=space['batch_size'], validation_data=(x_test, y_test), verbose=0, callbacks=callbacks_list)\n",
            "  13: \n",
            "  14:   val_loss, val_acc = model.evaluate(x_test, y_test, verbose=0)\n",
            "  15:   print('Test accuracy:', val_acc)\n",
            "  16:   print('Test loss:', val_loss)\n",
            "  17: \n",
            "  18:   \"\"\"\n",
            "  19:   history_dict = history.history\n",
            "  20:   loss_values = history_dict[\"loss\"]\n",
            "  21:   val_loss_values = history_dict[\"val_loss\"]\n",
            "  22: \n",
            "  23:   epochs = range(1, len(loss_values) + 1)\n",
            "  24:   \n",
            "  25:   plt.clf()\n",
            "  26:   # \"bo\"は\"blue dot(青のドット)を意味する\n",
            "  27:   plt.plot(epochs, loss_values, \"b\", label=\"Traning loss\")\n",
            "  28:   # \"b\"はsolod blue line(青の実線)を意味する\n",
            "  29:   plt.plot(epochs, val_loss_values, \"r\", label=\"Validation loss\")\n",
            "  30:   plt.title(\"Traning and validation loss\")\n",
            "  31:   plt.xlabel(\"Epochs\")\n",
            "  32:   plt.ylabel(\"Loss\")\n",
            "  33:   plt.legend()\n",
            "  34:   plt.show()\n",
            "  35:   \"\"\"\n",
            "  36: \n",
            "  37:   return {'loss': -val_acc, 'status': STATUS_OK, 'model': model}\n",
            "  38: \n",
            "CSV読み込み==============================================================================\n",
            "\n",
            "訓練テストデータ分割==============================================================================\n",
            "                       datetime     Open  ...        OBV  Target(30)\n",
            "0     2020-01-07 21:00:00+09:00   866195  ...    29511.0         0.0\n",
            "1     2020-01-07 23:00:00+09:00   871344  ...    17623.0         1.0\n",
            "2     2020-01-08 01:00:00+09:00   865210  ...     7662.0         1.0\n",
            "3     2020-01-08 03:00:00+09:00   858581  ...    21479.0         0.0\n",
            "4     2020-01-08 05:00:00+09:00   875212  ...    34391.0         0.0\n",
            "...                         ...      ...  ...        ...         ...\n",
            "5310  2021-03-26 09:00:00+09:00  6096755  ...  1778854.0         1.0\n",
            "5311  2021-03-26 11:00:00+09:00  5961052  ...  1779226.0         1.0\n",
            "5312  2021-03-26 13:00:00+09:00  6112689  ...  1779604.0         1.0\n",
            "5313  2021-03-26 15:00:00+09:00  6119037  ...  1779891.0         1.0\n",
            "5314  2021-03-26 17:00:00+09:00  6191538  ...  1780272.0         1.0\n",
            "\n",
            "[5315 rows x 1697 columns]\n",
            "          PPO1         macd1   macdsignal1  ...    TRANGE            AD        OBV\n",
            "0     0.668495   3244.051004   1037.109065  ...    6649.0  7.515876e+04   131918.0\n",
            "1     0.764617   3172.116654   1464.110583  ...    3828.0  7.358617e+04   134980.0\n",
            "2     0.653369   3046.084787   1780.505424  ...    4577.0  7.528299e+04   138458.0\n",
            "3     0.346027    732.880449   1570.980429  ...   16673.0  7.014005e+04   130576.0\n",
            "4     0.224967   2993.382297   1855.460803  ...   41499.0  7.520213e+04   142578.0\n",
            "...        ...           ...           ...  ...       ...           ...        ...\n",
            "4995 -0.337714 -25284.033857 -43215.566615  ...  169130.0  2.698175e+06  1778854.0\n",
            "4996  0.397736  -6115.562312 -35795.565755  ...  181868.0  2.698509e+06  1779226.0\n",
            "4997  0.672113   5911.971399 -27454.058324  ...  134549.0  2.698677e+06  1779604.0\n",
            "4998  0.922872  23110.052126 -17341.236234  ...  100349.0  2.698918e+06  1779891.0\n",
            "4999  1.064483  41754.305121  -5522.127963  ...  126932.0  2.699189e+06  1780272.0\n",
            "\n",
            "[5000 rows x 1688 columns]\n",
            "\n",
            "検証データ分割==============================================================================\n",
            "        PPO1         macd1   macdsignal1  ...    TRANGE            AD        OBV\n",
            "0   1.490107  43747.424626   4331.782555  ...   81358.0  2.698958e+06  1779926.0\n",
            "1   1.189075  33682.615591  10201.949162  ...  103658.0  2.698652e+06  1779525.0\n",
            "2   1.162086  35996.803657  15360.920061  ...   95000.0  2.699048e+06  1780042.0\n",
            "3   0.957496  26966.402987  17682.016646  ...   75519.0  2.698656e+06  1779559.0\n",
            "4   0.653181  29670.038804  20079.621078  ...  123500.0  2.698959e+06  1779948.0\n",
            "5   0.235954  27825.049928  21628.706848  ...   53422.0  2.698981e+06  1779787.0\n",
            "6   0.389997  38958.234788  25094.612436  ...   96509.0  2.699242e+06  1780048.0\n",
            "7   0.450503  52454.775936  30566.645136  ...  100521.0  2.699549e+06  1780413.0\n",
            "8   0.715090  48725.175597  34198.351228  ...  114917.0  2.699201e+06  1779973.0\n",
            "9   0.916564  45636.595073  36485.999997  ...   39221.0  2.699291e+06  1780130.0\n",
            "10  1.170120  48950.454479  38978.890893  ...   92126.0  2.699391e+06  1780359.0\n",
            "11  0.990979  42795.107824  39742.134279  ...   69674.0  2.699343e+06  1780138.0\n",
            "12  0.723427  37926.730386  39379.053501  ...   55917.0  2.699440e+06  1780352.0\n",
            "13  0.420445  21733.874184  35850.017637  ...   99957.0  2.699230e+06  1780092.0\n",
            "14  0.220023  15853.596608  31850.733432  ...  123086.0  2.699551e+06  1780468.0\n",
            "15 -0.104209  16769.893894  28834.565524  ...   65958.0  2.699713e+06  1780712.0\n",
            "16  0.036535  37149.698844  30497.592188  ...  153749.0  2.700038e+06  1781115.0\n",
            "17  0.216785  42263.550099  32850.783770  ...   43695.0  2.699995e+06  1780890.0\n",
            "18  0.633511  50959.981080  36472.623232  ...  109199.0  2.700197e+06  1781183.0\n",
            "19  0.927367  47489.550641  38676.008714  ...   86542.0  2.699915e+06  1780831.0\n",
            "20  1.207441  43832.827939  39707.372559  ...   58295.0  2.699999e+06  1781190.0\n",
            "21  1.004740  39051.868407  39576.271729  ...   51723.0  2.700100e+06  1781002.0\n",
            "22  0.940125  38938.959063  39448.809195  ...   55808.0  2.700133e+06  1781250.0\n",
            "23  0.559659  33753.192810  38309.685918  ...   58197.0  2.700166e+06  1781067.0\n",
            "24  0.303032  26275.763169  35902.901369  ...   64100.0  2.699966e+06  1780764.0\n",
            "25  0.002132  13249.088627  31372.138820  ...   62758.0  2.699705e+06  1780444.0\n",
            "26 -0.089441   4766.715324  26051.054121  ...  109440.0  2.699925e+06  1779887.0\n",
            "27 -0.186297  12789.256230  23398.694543  ...  118750.0  2.700136e+06  1780120.0\n",
            "28 -0.226352   8013.869074  20321.729449  ...   85348.0  2.700026e+06  1779959.0\n",
            "29 -0.406879  -8929.303865  14471.522786  ...  146415.0  2.699939e+06  1779699.0\n",
            "\n",
            "[30 rows x 1688 columns]\n",
            "RFE\n",
            "FIT\n",
            "Fitting estimator with 1688 features.\n",
            "Fitting estimator with 1687 features.\n",
            "Fitting estimator with 1686 features.\n",
            "Fitting estimator with 1685 features.\n",
            "Fitting estimator with 1684 features.\n",
            "Fitting estimator with 1683 features.\n",
            "Fitting estimator with 1682 features.\n",
            "Fitting estimator with 1681 features.\n",
            "Fitting estimator with 1680 features.\n",
            "Fitting estimator with 1679 features.\n",
            "Fitting estimator with 1678 features.\n",
            "Fitting estimator with 1677 features.\n",
            "Fitting estimator with 1676 features.\n",
            "Fitting estimator with 1675 features.\n",
            "Fitting estimator with 1674 features.\n",
            "Fitting estimator with 1673 features.\n",
            "Fitting estimator with 1672 features.\n",
            "Fitting estimator with 1671 features.\n",
            "Fitting estimator with 1670 features.\n",
            "Fitting estimator with 1669 features.\n",
            "Fitting estimator with 1668 features.\n",
            "Fitting estimator with 1667 features.\n",
            "Fitting estimator with 1666 features.\n",
            "Fitting estimator with 1665 features.\n",
            "Fitting estimator with 1664 features.\n",
            "Fitting estimator with 1663 features.\n",
            "Fitting estimator with 1662 features.\n",
            "Fitting estimator with 1661 features.\n",
            "Fitting estimator with 1660 features.\n",
            "Fitting estimator with 1659 features.\n",
            "Fitting estimator with 1658 features.\n",
            "Fitting estimator with 1657 features.\n",
            "Fitting estimator with 1656 features.\n",
            "Fitting estimator with 1655 features.\n",
            "Fitting estimator with 1654 features.\n",
            "Fitting estimator with 1653 features.\n",
            "Fitting estimator with 1652 features.\n",
            "Fitting estimator with 1651 features.\n",
            "Fitting estimator with 1650 features.\n",
            "Fitting estimator with 1649 features.\n",
            "Fitting estimator with 1648 features.\n",
            "Fitting estimator with 1647 features.\n",
            "Fitting estimator with 1646 features.\n",
            "Fitting estimator with 1645 features.\n",
            "Fitting estimator with 1644 features.\n",
            "Fitting estimator with 1643 features.\n",
            "Fitting estimator with 1642 features.\n",
            "Fitting estimator with 1641 features.\n",
            "Fitting estimator with 1640 features.\n",
            "Fitting estimator with 1639 features.\n",
            "Fitting estimator with 1638 features.\n",
            "Fitting estimator with 1637 features.\n",
            "Fitting estimator with 1636 features.\n",
            "Fitting estimator with 1635 features.\n",
            "Fitting estimator with 1634 features.\n",
            "Fitting estimator with 1633 features.\n",
            "Fitting estimator with 1632 features.\n",
            "Fitting estimator with 1631 features.\n",
            "Fitting estimator with 1630 features.\n",
            "Fitting estimator with 1629 features.\n",
            "Fitting estimator with 1628 features.\n",
            "Fitting estimator with 1627 features.\n",
            "Fitting estimator with 1626 features.\n",
            "Fitting estimator with 1625 features.\n",
            "Fitting estimator with 1624 features.\n",
            "Fitting estimator with 1623 features.\n",
            "Fitting estimator with 1622 features.\n",
            "Fitting estimator with 1621 features.\n",
            "Fitting estimator with 1620 features.\n",
            "Fitting estimator with 1619 features.\n",
            "Fitting estimator with 1618 features.\n",
            "Fitting estimator with 1617 features.\n",
            "Fitting estimator with 1616 features.\n",
            "Fitting estimator with 1615 features.\n",
            "Fitting estimator with 1614 features.\n",
            "Fitting estimator with 1613 features.\n",
            "Fitting estimator with 1612 features.\n",
            "Fitting estimator with 1611 features.\n",
            "Fitting estimator with 1610 features.\n",
            "Fitting estimator with 1609 features.\n",
            "Fitting estimator with 1608 features.\n",
            "Fitting estimator with 1607 features.\n",
            "Fitting estimator with 1606 features.\n",
            "Fitting estimator with 1605 features.\n",
            "Fitting estimator with 1604 features.\n",
            "Fitting estimator with 1603 features.\n",
            "Fitting estimator with 1602 features.\n",
            "Fitting estimator with 1601 features.\n",
            "Fitting estimator with 1600 features.\n",
            "Fitting estimator with 1599 features.\n",
            "Fitting estimator with 1598 features.\n",
            "Fitting estimator with 1597 features.\n",
            "Fitting estimator with 1596 features.\n",
            "Fitting estimator with 1595 features.\n",
            "Fitting estimator with 1594 features.\n",
            "Fitting estimator with 1593 features.\n",
            "Fitting estimator with 1592 features.\n",
            "Fitting estimator with 1591 features.\n",
            "Fitting estimator with 1590 features.\n",
            "Fitting estimator with 1589 features.\n",
            "Fitting estimator with 1588 features.\n",
            "Fitting estimator with 1587 features.\n",
            "Fitting estimator with 1586 features.\n",
            "Fitting estimator with 1585 features.\n",
            "Fitting estimator with 1584 features.\n",
            "Fitting estimator with 1583 features.\n",
            "Fitting estimator with 1582 features.\n",
            "Fitting estimator with 1581 features.\n",
            "Fitting estimator with 1580 features.\n",
            "Fitting estimator with 1579 features.\n",
            "Fitting estimator with 1578 features.\n",
            "Fitting estimator with 1577 features.\n",
            "Fitting estimator with 1576 features.\n",
            "Fitting estimator with 1575 features.\n",
            "Fitting estimator with 1574 features.\n",
            "Fitting estimator with 1573 features.\n",
            "Fitting estimator with 1572 features.\n",
            "Fitting estimator with 1571 features.\n",
            "Fitting estimator with 1570 features.\n",
            "Fitting estimator with 1569 features.\n",
            "Fitting estimator with 1568 features.\n",
            "Fitting estimator with 1567 features.\n",
            "Fitting estimator with 1566 features.\n",
            "Fitting estimator with 1565 features.\n",
            "Fitting estimator with 1564 features.\n",
            "Fitting estimator with 1563 features.\n",
            "Fitting estimator with 1562 features.\n",
            "Fitting estimator with 1561 features.\n",
            "Fitting estimator with 1560 features.\n",
            "Fitting estimator with 1559 features.\n",
            "Fitting estimator with 1558 features.\n",
            "Fitting estimator with 1557 features.\n",
            "Fitting estimator with 1556 features.\n",
            "Fitting estimator with 1555 features.\n",
            "Fitting estimator with 1554 features.\n",
            "Fitting estimator with 1553 features.\n",
            "Fitting estimator with 1552 features.\n",
            "Fitting estimator with 1551 features.\n",
            "Fitting estimator with 1550 features.\n",
            "Fitting estimator with 1549 features.\n",
            "Fitting estimator with 1548 features.\n",
            "Fitting estimator with 1547 features.\n",
            "Fitting estimator with 1546 features.\n",
            "Fitting estimator with 1545 features.\n",
            "Fitting estimator with 1544 features.\n",
            "Fitting estimator with 1543 features.\n",
            "Fitting estimator with 1542 features.\n",
            "Fitting estimator with 1541 features.\n",
            "Fitting estimator with 1540 features.\n",
            "Fitting estimator with 1539 features.\n",
            "Fitting estimator with 1538 features.\n",
            "Fitting estimator with 1537 features.\n",
            "Fitting estimator with 1536 features.\n",
            "Fitting estimator with 1535 features.\n",
            "Fitting estimator with 1534 features.\n",
            "Fitting estimator with 1533 features.\n",
            "Fitting estimator with 1532 features.\n",
            "Fitting estimator with 1531 features.\n",
            "Fitting estimator with 1530 features.\n",
            "Fitting estimator with 1529 features.\n",
            "Fitting estimator with 1528 features.\n",
            "Fitting estimator with 1527 features.\n",
            "Fitting estimator with 1526 features.\n",
            "Fitting estimator with 1525 features.\n",
            "Fitting estimator with 1524 features.\n",
            "Fitting estimator with 1523 features.\n",
            "Fitting estimator with 1522 features.\n",
            "Fitting estimator with 1521 features.\n",
            "Fitting estimator with 1520 features.\n",
            "Fitting estimator with 1519 features.\n",
            "Fitting estimator with 1518 features.\n",
            "Fitting estimator with 1517 features.\n",
            "Fitting estimator with 1516 features.\n",
            "Fitting estimator with 1515 features.\n",
            "Fitting estimator with 1514 features.\n",
            "Fitting estimator with 1513 features.\n",
            "Fitting estimator with 1512 features.\n",
            "Fitting estimator with 1511 features.\n",
            "Fitting estimator with 1510 features.\n",
            "Fitting estimator with 1509 features.\n",
            "Fitting estimator with 1508 features.\n",
            "Fitting estimator with 1507 features.\n",
            "Fitting estimator with 1506 features.\n",
            "Fitting estimator with 1505 features.\n",
            "Fitting estimator with 1504 features.\n",
            "Fitting estimator with 1503 features.\n",
            "Fitting estimator with 1502 features.\n",
            "Fitting estimator with 1501 features.\n",
            "Fitting estimator with 1500 features.\n",
            "Fitting estimator with 1499 features.\n",
            "Fitting estimator with 1498 features.\n",
            "Fitting estimator with 1497 features.\n",
            "Fitting estimator with 1496 features.\n",
            "Fitting estimator with 1495 features.\n",
            "Fitting estimator with 1494 features.\n",
            "Fitting estimator with 1493 features.\n",
            "Fitting estimator with 1492 features.\n",
            "Fitting estimator with 1491 features.\n",
            "Fitting estimator with 1490 features.\n",
            "Fitting estimator with 1489 features.\n",
            "Fitting estimator with 1488 features.\n",
            "Fitting estimator with 1487 features.\n",
            "Fitting estimator with 1486 features.\n",
            "Fitting estimator with 1485 features.\n",
            "Fitting estimator with 1484 features.\n",
            "Fitting estimator with 1483 features.\n",
            "Fitting estimator with 1482 features.\n",
            "Fitting estimator with 1481 features.\n",
            "Fitting estimator with 1480 features.\n",
            "Fitting estimator with 1479 features.\n",
            "Fitting estimator with 1478 features.\n",
            "Fitting estimator with 1477 features.\n",
            "Fitting estimator with 1476 features.\n",
            "Fitting estimator with 1475 features.\n",
            "Fitting estimator with 1474 features.\n",
            "Fitting estimator with 1473 features.\n",
            "Fitting estimator with 1472 features.\n",
            "Fitting estimator with 1471 features.\n",
            "Fitting estimator with 1470 features.\n",
            "Fitting estimator with 1469 features.\n",
            "Fitting estimator with 1468 features.\n",
            "Fitting estimator with 1467 features.\n",
            "Fitting estimator with 1466 features.\n",
            "Fitting estimator with 1465 features.\n",
            "Fitting estimator with 1464 features.\n",
            "Fitting estimator with 1463 features.\n",
            "Fitting estimator with 1462 features.\n",
            "Fitting estimator with 1461 features.\n",
            "Fitting estimator with 1460 features.\n",
            "Fitting estimator with 1459 features.\n",
            "Fitting estimator with 1458 features.\n",
            "Fitting estimator with 1457 features.\n",
            "Fitting estimator with 1456 features.\n",
            "Fitting estimator with 1455 features.\n",
            "Fitting estimator with 1454 features.\n",
            "Fitting estimator with 1453 features.\n",
            "Fitting estimator with 1452 features.\n",
            "Fitting estimator with 1451 features.\n",
            "Fitting estimator with 1450 features.\n",
            "Fitting estimator with 1449 features.\n",
            "Fitting estimator with 1448 features.\n",
            "Fitting estimator with 1447 features.\n",
            "Fitting estimator with 1446 features.\n",
            "Fitting estimator with 1445 features.\n",
            "Fitting estimator with 1444 features.\n",
            "Fitting estimator with 1443 features.\n",
            "Fitting estimator with 1442 features.\n",
            "Fitting estimator with 1441 features.\n",
            "Fitting estimator with 1440 features.\n",
            "Fitting estimator with 1439 features.\n",
            "Fitting estimator with 1438 features.\n",
            "Fitting estimator with 1437 features.\n",
            "Fitting estimator with 1436 features.\n",
            "Fitting estimator with 1435 features.\n",
            "Fitting estimator with 1434 features.\n",
            "Fitting estimator with 1433 features.\n",
            "Fitting estimator with 1432 features.\n",
            "Fitting estimator with 1431 features.\n",
            "Fitting estimator with 1430 features.\n",
            "Fitting estimator with 1429 features.\n",
            "Fitting estimator with 1428 features.\n",
            "Fitting estimator with 1427 features.\n",
            "Fitting estimator with 1426 features.\n",
            "Fitting estimator with 1425 features.\n",
            "Fitting estimator with 1424 features.\n",
            "Fitting estimator with 1423 features.\n",
            "Fitting estimator with 1422 features.\n",
            "Fitting estimator with 1421 features.\n",
            "Fitting estimator with 1420 features.\n",
            "Fitting estimator with 1419 features.\n",
            "Fitting estimator with 1418 features.\n",
            "Fitting estimator with 1417 features.\n",
            "Fitting estimator with 1416 features.\n",
            "Fitting estimator with 1415 features.\n",
            "Fitting estimator with 1414 features.\n",
            "Fitting estimator with 1413 features.\n",
            "Fitting estimator with 1412 features.\n",
            "Fitting estimator with 1411 features.\n",
            "Fitting estimator with 1410 features.\n",
            "Fitting estimator with 1409 features.\n",
            "Fitting estimator with 1408 features.\n",
            "Fitting estimator with 1407 features.\n",
            "Fitting estimator with 1406 features.\n",
            "Fitting estimator with 1405 features.\n",
            "Fitting estimator with 1404 features.\n",
            "Fitting estimator with 1403 features.\n",
            "Fitting estimator with 1402 features.\n",
            "Fitting estimator with 1401 features.\n",
            "Fitting estimator with 1400 features.\n",
            "Fitting estimator with 1399 features.\n",
            "Fitting estimator with 1398 features.\n",
            "Fitting estimator with 1397 features.\n",
            "Fitting estimator with 1396 features.\n",
            "Fitting estimator with 1395 features.\n",
            "Fitting estimator with 1394 features.\n",
            "Fitting estimator with 1393 features.\n",
            "Fitting estimator with 1392 features.\n",
            "Fitting estimator with 1391 features.\n",
            "Fitting estimator with 1390 features.\n",
            "Fitting estimator with 1389 features.\n",
            "Fitting estimator with 1388 features.\n",
            "Fitting estimator with 1387 features.\n",
            "Fitting estimator with 1386 features.\n",
            "Fitting estimator with 1385 features.\n",
            "Fitting estimator with 1384 features.\n",
            "Fitting estimator with 1383 features.\n",
            "Fitting estimator with 1382 features.\n",
            "Fitting estimator with 1381 features.\n",
            "Fitting estimator with 1380 features.\n",
            "Fitting estimator with 1379 features.\n",
            "Fitting estimator with 1378 features.\n",
            "Fitting estimator with 1377 features.\n",
            "Fitting estimator with 1376 features.\n",
            "Fitting estimator with 1375 features.\n",
            "Fitting estimator with 1374 features.\n",
            "Fitting estimator with 1373 features.\n",
            "Fitting estimator with 1372 features.\n",
            "Fitting estimator with 1371 features.\n",
            "Fitting estimator with 1370 features.\n",
            "Fitting estimator with 1369 features.\n",
            "Fitting estimator with 1368 features.\n",
            "Fitting estimator with 1367 features.\n",
            "Fitting estimator with 1366 features.\n",
            "Fitting estimator with 1365 features.\n",
            "Fitting estimator with 1364 features.\n",
            "Fitting estimator with 1363 features.\n",
            "Fitting estimator with 1362 features.\n",
            "Fitting estimator with 1361 features.\n",
            "Fitting estimator with 1360 features.\n",
            "Fitting estimator with 1359 features.\n",
            "Fitting estimator with 1358 features.\n",
            "Fitting estimator with 1357 features.\n",
            "Fitting estimator with 1356 features.\n",
            "Fitting estimator with 1355 features.\n",
            "Fitting estimator with 1354 features.\n",
            "Fitting estimator with 1353 features.\n",
            "Fitting estimator with 1352 features.\n",
            "Fitting estimator with 1351 features.\n",
            "Fitting estimator with 1350 features.\n",
            "Fitting estimator with 1349 features.\n",
            "Fitting estimator with 1348 features.\n",
            "Fitting estimator with 1347 features.\n",
            "Fitting estimator with 1346 features.\n",
            "Fitting estimator with 1345 features.\n",
            "Fitting estimator with 1344 features.\n",
            "Fitting estimator with 1343 features.\n",
            "Fitting estimator with 1342 features.\n",
            "Fitting estimator with 1341 features.\n",
            "Fitting estimator with 1340 features.\n",
            "Fitting estimator with 1339 features.\n",
            "Fitting estimator with 1338 features.\n",
            "Fitting estimator with 1337 features.\n",
            "Fitting estimator with 1336 features.\n",
            "Fitting estimator with 1335 features.\n",
            "Fitting estimator with 1334 features.\n",
            "Fitting estimator with 1333 features.\n",
            "Fitting estimator with 1332 features.\n",
            "Fitting estimator with 1331 features.\n",
            "Fitting estimator with 1330 features.\n",
            "Fitting estimator with 1329 features.\n",
            "Fitting estimator with 1328 features.\n",
            "Fitting estimator with 1327 features.\n",
            "Fitting estimator with 1326 features.\n",
            "Fitting estimator with 1325 features.\n",
            "Fitting estimator with 1324 features.\n",
            "Fitting estimator with 1323 features.\n",
            "Fitting estimator with 1322 features.\n",
            "Fitting estimator with 1321 features.\n",
            "Fitting estimator with 1320 features.\n",
            "Fitting estimator with 1319 features.\n",
            "Fitting estimator with 1318 features.\n",
            "Fitting estimator with 1317 features.\n",
            "Fitting estimator with 1316 features.\n",
            "Fitting estimator with 1315 features.\n",
            "Fitting estimator with 1314 features.\n",
            "Fitting estimator with 1313 features.\n",
            "Fitting estimator with 1312 features.\n",
            "Fitting estimator with 1311 features.\n",
            "Fitting estimator with 1310 features.\n",
            "Fitting estimator with 1309 features.\n",
            "Fitting estimator with 1308 features.\n",
            "Fitting estimator with 1307 features.\n",
            "Fitting estimator with 1306 features.\n",
            "Fitting estimator with 1305 features.\n",
            "Fitting estimator with 1304 features.\n",
            "Fitting estimator with 1303 features.\n",
            "Fitting estimator with 1302 features.\n",
            "Fitting estimator with 1301 features.\n",
            "Fitting estimator with 1300 features.\n",
            "Fitting estimator with 1299 features.\n",
            "Fitting estimator with 1298 features.\n",
            "Fitting estimator with 1297 features.\n",
            "Fitting estimator with 1296 features.\n",
            "Fitting estimator with 1295 features.\n",
            "Fitting estimator with 1294 features.\n",
            "Fitting estimator with 1293 features.\n",
            "Fitting estimator with 1292 features.\n",
            "Fitting estimator with 1291 features.\n",
            "Fitting estimator with 1290 features.\n",
            "Fitting estimator with 1289 features.\n",
            "Fitting estimator with 1288 features.\n",
            "Fitting estimator with 1287 features.\n",
            "Fitting estimator with 1286 features.\n",
            "Fitting estimator with 1285 features.\n",
            "Fitting estimator with 1284 features.\n",
            "Fitting estimator with 1283 features.\n",
            "Fitting estimator with 1282 features.\n",
            "Fitting estimator with 1281 features.\n",
            "Fitting estimator with 1280 features.\n",
            "Fitting estimator with 1279 features.\n",
            "Fitting estimator with 1278 features.\n",
            "Fitting estimator with 1277 features.\n",
            "Fitting estimator with 1276 features.\n",
            "Fitting estimator with 1275 features.\n",
            "Fitting estimator with 1274 features.\n",
            "Fitting estimator with 1273 features.\n",
            "Fitting estimator with 1272 features.\n",
            "Fitting estimator with 1271 features.\n",
            "Fitting estimator with 1270 features.\n",
            "Fitting estimator with 1269 features.\n",
            "Fitting estimator with 1268 features.\n",
            "Fitting estimator with 1267 features.\n",
            "Fitting estimator with 1266 features.\n",
            "Fitting estimator with 1265 features.\n",
            "Fitting estimator with 1264 features.\n",
            "Fitting estimator with 1263 features.\n",
            "Fitting estimator with 1262 features.\n",
            "Fitting estimator with 1261 features.\n",
            "Fitting estimator with 1260 features.\n",
            "Fitting estimator with 1259 features.\n",
            "Fitting estimator with 1258 features.\n",
            "Fitting estimator with 1257 features.\n",
            "Fitting estimator with 1256 features.\n",
            "Fitting estimator with 1255 features.\n",
            "Fitting estimator with 1254 features.\n",
            "Fitting estimator with 1253 features.\n",
            "Fitting estimator with 1252 features.\n",
            "Fitting estimator with 1251 features.\n",
            "Fitting estimator with 1250 features.\n",
            "Fitting estimator with 1249 features.\n",
            "Fitting estimator with 1248 features.\n",
            "Fitting estimator with 1247 features.\n",
            "Fitting estimator with 1246 features.\n",
            "Fitting estimator with 1245 features.\n",
            "Fitting estimator with 1244 features.\n",
            "Fitting estimator with 1243 features.\n",
            "Fitting estimator with 1242 features.\n",
            "Fitting estimator with 1241 features.\n",
            "Fitting estimator with 1240 features.\n",
            "Fitting estimator with 1239 features.\n",
            "Fitting estimator with 1238 features.\n",
            "Fitting estimator with 1237 features.\n",
            "Fitting estimator with 1236 features.\n",
            "Fitting estimator with 1235 features.\n",
            "Fitting estimator with 1234 features.\n",
            "Fitting estimator with 1233 features.\n",
            "Fitting estimator with 1232 features.\n",
            "Fitting estimator with 1231 features.\n",
            "Fitting estimator with 1230 features.\n",
            "Fitting estimator with 1229 features.\n",
            "Fitting estimator with 1228 features.\n",
            "Fitting estimator with 1227 features.\n",
            "Fitting estimator with 1226 features.\n",
            "Fitting estimator with 1225 features.\n",
            "Fitting estimator with 1224 features.\n",
            "Fitting estimator with 1223 features.\n",
            "Fitting estimator with 1222 features.\n",
            "Fitting estimator with 1221 features.\n",
            "Fitting estimator with 1220 features.\n",
            "Fitting estimator with 1219 features.\n",
            "Fitting estimator with 1218 features.\n",
            "Fitting estimator with 1217 features.\n",
            "Fitting estimator with 1216 features.\n",
            "Fitting estimator with 1215 features.\n",
            "Fitting estimator with 1214 features.\n",
            "Fitting estimator with 1213 features.\n",
            "Fitting estimator with 1212 features.\n",
            "Fitting estimator with 1211 features.\n",
            "Fitting estimator with 1210 features.\n",
            "Fitting estimator with 1209 features.\n",
            "Fitting estimator with 1208 features.\n",
            "Fitting estimator with 1207 features.\n",
            "Fitting estimator with 1206 features.\n",
            "Fitting estimator with 1205 features.\n",
            "Fitting estimator with 1204 features.\n",
            "Fitting estimator with 1203 features.\n",
            "Fitting estimator with 1202 features.\n",
            "Fitting estimator with 1201 features.\n",
            "Fitting estimator with 1200 features.\n",
            "Fitting estimator with 1199 features.\n",
            "Fitting estimator with 1198 features.\n",
            "Fitting estimator with 1197 features.\n",
            "Fitting estimator with 1196 features.\n",
            "Fitting estimator with 1195 features.\n",
            "Fitting estimator with 1194 features.\n",
            "Fitting estimator with 1193 features.\n",
            "Fitting estimator with 1192 features.\n",
            "Fitting estimator with 1191 features.\n",
            "Fitting estimator with 1190 features.\n",
            "Fitting estimator with 1189 features.\n",
            "Fitting estimator with 1188 features.\n",
            "Fitting estimator with 1187 features.\n",
            "Fitting estimator with 1186 features.\n",
            "Fitting estimator with 1185 features.\n",
            "Fitting estimator with 1184 features.\n",
            "Fitting estimator with 1183 features.\n",
            "Fitting estimator with 1182 features.\n",
            "Fitting estimator with 1181 features.\n",
            "Fitting estimator with 1180 features.\n",
            "Fitting estimator with 1179 features.\n",
            "Fitting estimator with 1178 features.\n",
            "Fitting estimator with 1177 features.\n",
            "Fitting estimator with 1176 features.\n",
            "Fitting estimator with 1175 features.\n",
            "Fitting estimator with 1174 features.\n",
            "Fitting estimator with 1173 features.\n",
            "Fitting estimator with 1172 features.\n",
            "Fitting estimator with 1171 features.\n",
            "Fitting estimator with 1170 features.\n",
            "Fitting estimator with 1169 features.\n",
            "Fitting estimator with 1168 features.\n",
            "Fitting estimator with 1167 features.\n",
            "Fitting estimator with 1166 features.\n",
            "Fitting estimator with 1165 features.\n",
            "Fitting estimator with 1164 features.\n",
            "Fitting estimator with 1163 features.\n",
            "Fitting estimator with 1162 features.\n",
            "Fitting estimator with 1161 features.\n",
            "Fitting estimator with 1160 features.\n",
            "Fitting estimator with 1159 features.\n",
            "Fitting estimator with 1158 features.\n",
            "Fitting estimator with 1157 features.\n",
            "Fitting estimator with 1156 features.\n",
            "Fitting estimator with 1155 features.\n",
            "Fitting estimator with 1154 features.\n",
            "Fitting estimator with 1153 features.\n",
            "Fitting estimator with 1152 features.\n",
            "Fitting estimator with 1151 features.\n",
            "Fitting estimator with 1150 features.\n",
            "Fitting estimator with 1149 features.\n",
            "Fitting estimator with 1148 features.\n",
            "Fitting estimator with 1147 features.\n",
            "Fitting estimator with 1146 features.\n",
            "Fitting estimator with 1145 features.\n",
            "Fitting estimator with 1144 features.\n",
            "Fitting estimator with 1143 features.\n",
            "Fitting estimator with 1142 features.\n",
            "Fitting estimator with 1141 features.\n",
            "Fitting estimator with 1140 features.\n",
            "Fitting estimator with 1139 features.\n",
            "Fitting estimator with 1138 features.\n",
            "Fitting estimator with 1137 features.\n",
            "Fitting estimator with 1136 features.\n",
            "Fitting estimator with 1135 features.\n",
            "Fitting estimator with 1134 features.\n",
            "Fitting estimator with 1133 features.\n",
            "Fitting estimator with 1132 features.\n",
            "Fitting estimator with 1131 features.\n",
            "Fitting estimator with 1130 features.\n",
            "Fitting estimator with 1129 features.\n",
            "Fitting estimator with 1128 features.\n",
            "Fitting estimator with 1127 features.\n",
            "Fitting estimator with 1126 features.\n",
            "Fitting estimator with 1125 features.\n",
            "Fitting estimator with 1124 features.\n",
            "Fitting estimator with 1123 features.\n",
            "Fitting estimator with 1122 features.\n",
            "Fitting estimator with 1121 features.\n",
            "Fitting estimator with 1120 features.\n",
            "Fitting estimator with 1119 features.\n",
            "Fitting estimator with 1118 features.\n",
            "Fitting estimator with 1117 features.\n",
            "Fitting estimator with 1116 features.\n",
            "Fitting estimator with 1115 features.\n",
            "Fitting estimator with 1114 features.\n",
            "Fitting estimator with 1113 features.\n",
            "Fitting estimator with 1112 features.\n",
            "Fitting estimator with 1111 features.\n",
            "Fitting estimator with 1110 features.\n",
            "Fitting estimator with 1109 features.\n",
            "Fitting estimator with 1108 features.\n",
            "Fitting estimator with 1107 features.\n",
            "Fitting estimator with 1106 features.\n",
            "Fitting estimator with 1105 features.\n",
            "Fitting estimator with 1104 features.\n",
            "Fitting estimator with 1103 features.\n",
            "Fitting estimator with 1102 features.\n",
            "Fitting estimator with 1101 features.\n",
            "Fitting estimator with 1100 features.\n",
            "Fitting estimator with 1099 features.\n",
            "Fitting estimator with 1098 features.\n",
            "Fitting estimator with 1097 features.\n",
            "Fitting estimator with 1096 features.\n",
            "Fitting estimator with 1095 features.\n",
            "Fitting estimator with 1094 features.\n",
            "Fitting estimator with 1093 features.\n",
            "Fitting estimator with 1092 features.\n",
            "Fitting estimator with 1091 features.\n",
            "Fitting estimator with 1090 features.\n",
            "Fitting estimator with 1089 features.\n",
            "Fitting estimator with 1088 features.\n",
            "Fitting estimator with 1087 features.\n",
            "Fitting estimator with 1086 features.\n",
            "Fitting estimator with 1085 features.\n",
            "Fitting estimator with 1084 features.\n",
            "Fitting estimator with 1083 features.\n",
            "Fitting estimator with 1082 features.\n",
            "Fitting estimator with 1081 features.\n",
            "Fitting estimator with 1080 features.\n",
            "Fitting estimator with 1079 features.\n",
            "Fitting estimator with 1078 features.\n",
            "Fitting estimator with 1077 features.\n",
            "Fitting estimator with 1076 features.\n",
            "Fitting estimator with 1075 features.\n",
            "Fitting estimator with 1074 features.\n",
            "Fitting estimator with 1073 features.\n",
            "Fitting estimator with 1072 features.\n",
            "Fitting estimator with 1071 features.\n",
            "Fitting estimator with 1070 features.\n",
            "Fitting estimator with 1069 features.\n",
            "Fitting estimator with 1068 features.\n",
            "Fitting estimator with 1067 features.\n",
            "Fitting estimator with 1066 features.\n",
            "Fitting estimator with 1065 features.\n",
            "Fitting estimator with 1064 features.\n",
            "Fitting estimator with 1063 features.\n",
            "Fitting estimator with 1062 features.\n",
            "Fitting estimator with 1061 features.\n",
            "Fitting estimator with 1060 features.\n",
            "Fitting estimator with 1059 features.\n",
            "Fitting estimator with 1058 features.\n",
            "Fitting estimator with 1057 features.\n",
            "Fitting estimator with 1056 features.\n",
            "Fitting estimator with 1055 features.\n",
            "Fitting estimator with 1054 features.\n",
            "Fitting estimator with 1053 features.\n",
            "Fitting estimator with 1052 features.\n",
            "Fitting estimator with 1051 features.\n",
            "Fitting estimator with 1050 features.\n",
            "Fitting estimator with 1049 features.\n",
            "Fitting estimator with 1048 features.\n",
            "Fitting estimator with 1047 features.\n",
            "Fitting estimator with 1046 features.\n",
            "Fitting estimator with 1045 features.\n",
            "Fitting estimator with 1044 features.\n",
            "Fitting estimator with 1043 features.\n",
            "Fitting estimator with 1042 features.\n",
            "Fitting estimator with 1041 features.\n",
            "Fitting estimator with 1040 features.\n",
            "Fitting estimator with 1039 features.\n",
            "Fitting estimator with 1038 features.\n",
            "Fitting estimator with 1037 features.\n",
            "Fitting estimator with 1036 features.\n",
            "Fitting estimator with 1035 features.\n",
            "Fitting estimator with 1034 features.\n",
            "Fitting estimator with 1033 features.\n",
            "Fitting estimator with 1032 features.\n",
            "Fitting estimator with 1031 features.\n",
            "Fitting estimator with 1030 features.\n",
            "Fitting estimator with 1029 features.\n",
            "Fitting estimator with 1028 features.\n",
            "Fitting estimator with 1027 features.\n",
            "Fitting estimator with 1026 features.\n",
            "Fitting estimator with 1025 features.\n",
            "Fitting estimator with 1024 features.\n",
            "Fitting estimator with 1023 features.\n",
            "Fitting estimator with 1022 features.\n",
            "Fitting estimator with 1021 features.\n",
            "Fitting estimator with 1020 features.\n",
            "Fitting estimator with 1019 features.\n",
            "Fitting estimator with 1018 features.\n",
            "Fitting estimator with 1017 features.\n",
            "Fitting estimator with 1016 features.\n",
            "Fitting estimator with 1015 features.\n",
            "Fitting estimator with 1014 features.\n",
            "Fitting estimator with 1013 features.\n",
            "Fitting estimator with 1012 features.\n",
            "Fitting estimator with 1011 features.\n",
            "Fitting estimator with 1010 features.\n",
            "Fitting estimator with 1009 features.\n",
            "Fitting estimator with 1008 features.\n",
            "Fitting estimator with 1007 features.\n",
            "Fitting estimator with 1006 features.\n",
            "Fitting estimator with 1005 features.\n",
            "Fitting estimator with 1004 features.\n",
            "Fitting estimator with 1003 features.\n",
            "Fitting estimator with 1002 features.\n",
            "Fitting estimator with 1001 features.\n",
            "Fitting estimator with 1000 features.\n",
            "Fitting estimator with 999 features.\n",
            "Fitting estimator with 998 features.\n",
            "Fitting estimator with 997 features.\n",
            "Fitting estimator with 996 features.\n",
            "Fitting estimator with 995 features.\n",
            "Fitting estimator with 994 features.\n",
            "Fitting estimator with 993 features.\n",
            "Fitting estimator with 992 features.\n",
            "Fitting estimator with 991 features.\n",
            "Fitting estimator with 990 features.\n",
            "Fitting estimator with 989 features.\n",
            "Fitting estimator with 988 features.\n",
            "Fitting estimator with 987 features.\n",
            "Fitting estimator with 986 features.\n",
            "Fitting estimator with 985 features.\n",
            "Fitting estimator with 984 features.\n",
            "Fitting estimator with 983 features.\n",
            "Fitting estimator with 982 features.\n",
            "Fitting estimator with 981 features.\n",
            "Fitting estimator with 980 features.\n",
            "Fitting estimator with 979 features.\n",
            "Fitting estimator with 978 features.\n",
            "Fitting estimator with 977 features.\n",
            "Fitting estimator with 976 features.\n",
            "Fitting estimator with 975 features.\n",
            "Fitting estimator with 974 features.\n",
            "Fitting estimator with 973 features.\n",
            "Fitting estimator with 972 features.\n",
            "Fitting estimator with 971 features.\n",
            "Fitting estimator with 970 features.\n",
            "Fitting estimator with 969 features.\n",
            "Fitting estimator with 968 features.\n",
            "Fitting estimator with 967 features.\n",
            "Fitting estimator with 966 features.\n",
            "Fitting estimator with 965 features.\n",
            "Fitting estimator with 964 features.\n",
            "Fitting estimator with 963 features.\n",
            "Fitting estimator with 962 features.\n",
            "Fitting estimator with 961 features.\n",
            "Fitting estimator with 960 features.\n",
            "Fitting estimator with 959 features.\n",
            "Fitting estimator with 958 features.\n",
            "Fitting estimator with 957 features.\n",
            "Fitting estimator with 956 features.\n",
            "Fitting estimator with 955 features.\n",
            "Fitting estimator with 954 features.\n",
            "Fitting estimator with 953 features.\n",
            "Fitting estimator with 952 features.\n",
            "Fitting estimator with 951 features.\n",
            "Fitting estimator with 950 features.\n",
            "Fitting estimator with 949 features.\n",
            "Fitting estimator with 948 features.\n",
            "Fitting estimator with 947 features.\n",
            "Fitting estimator with 946 features.\n",
            "Fitting estimator with 945 features.\n",
            "Fitting estimator with 944 features.\n",
            "Fitting estimator with 943 features.\n",
            "Fitting estimator with 942 features.\n",
            "Fitting estimator with 941 features.\n",
            "Fitting estimator with 940 features.\n",
            "Fitting estimator with 939 features.\n",
            "Fitting estimator with 938 features.\n",
            "Fitting estimator with 937 features.\n",
            "Fitting estimator with 936 features.\n",
            "Fitting estimator with 935 features.\n",
            "Fitting estimator with 934 features.\n",
            "Fitting estimator with 933 features.\n",
            "Fitting estimator with 932 features.\n",
            "Fitting estimator with 931 features.\n",
            "Fitting estimator with 930 features.\n",
            "Fitting estimator with 929 features.\n",
            "Fitting estimator with 928 features.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL94kAN_3cDI"
      },
      "source": [
        "y_pred_proba = best_model.predict(x_test)\n",
        "y_pred = np.where(y_pred_proba > 0.5, 1, 0)\n",
        "print(\"CSV読み込み==============================================================================\")\n",
        "df1 = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/feature_data_test.csv\")\n",
        "df1 = df1[0:len(df1) - 30]\n",
        "display(df1)\n",
        "df1 = df1[-5000:]\n",
        "df1 = df1.reset_index()\n",
        "df1 = df1[-500:]\n",
        "df1[\"target\"] = y_pred\n",
        "display(df1)\n",
        "pd.DataFrame(df1).to_csv(\"/content/drive/My Drive/Colab Notebooks/keras_pre.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM1IBjHLmsmz"
      },
      "source": [
        "#best_model.save(\"/content/drive/My Drive/Colab Notebooks/my_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yqOwab-oVNO"
      },
      "source": [
        "#new_model = keras.models.load_model(\"/content/drive/My Drive/Colab Notebooks/my_model.h5\")\n",
        "#print(new_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdBykZ07ftgx"
      },
      "source": [
        "\"\"\"\n",
        "sum(df1[\"Target(30)\"] == df1[\"target\"])\n",
        "print(sum(df1[\"Target(30)\"] == df1[\"target\"]) / len(df1[\"Target(30)\"]))\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBT5qWq1LMBP"
      },
      "source": [
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(Dense(384, activation=\"tanh\", input_shape=(x_train.shape[1],)))\n",
        "model.add(Dropout(0.9633154977822115))\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dropout(0.7168429952431055))\n",
        "model.add(Dense(384, activation=\"tanh\"))\n",
        "model.add(Dropout(0.845687831736537))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "sgd = SGD(lr=0.01, momentum=0.9, decay=1e-4, nesterov=True)\n",
        "model.compile(optimizer=\"adamax\", loss=\"mse\", metrics=[\"acc\"])\n",
        "\"\"\"\n",
        "# hourないver\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(Dense(768, activation=\"tanh\", input_shape=(x_train.shape[1],)))\n",
        "model.add(Dropout(0.990002599701736))\n",
        "model.add(Dense(384, activation=\"tanh\"))\n",
        "model.add(Dropout(0.39853942914582385))\n",
        "model.add(Dense(128, activation=\"tanh\"))\n",
        "model.add(Dropout(0.9172213806474925))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "sgd = SGD(lr=0.01, momentum=0.9, decay=1e-4, nesterov=True)\n",
        "model.compile(optimizer=\"adamax\", loss=\"mse\", metrics=[\"acc\"])\n",
        "callbacks_list = [EarlyStopping(monitor=\"val_loss\", patience=10)]\n",
        "history = model.fit(x_train, y_train, epochs=1000, batch_size=512, validation_data=(x_test, y_test), verbose=0, callbacks=callbacks_list)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QidkZViVjMex"
      },
      "source": [
        "\"\"\"\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_train1 = x_train.reshape(-1, 1, 259)\n",
        "x_test1  = x_test.reshape(-1, 1, 259)\n",
        "y_train1 = y_train.reshape(-1, 1, 1)\n",
        "y_test1 = y_test.reshape(-1, 1, 1)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.LSTM(512,input_shape=(1, 259),\n",
        "                          return_sequences = True),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(128),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.LSTM(30,\n",
        "            return_sequences=False),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "x_train, y_train, x_test, y_test = data()\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation=\"relu\", input_shape=(x_train.shape[1],)))\n",
        "model.add(Dropout(0.6863068699311096))\n",
        "model.add(Dense(1024, activation=\"tanh\"))\n",
        "model.add(Dropout(0.7534624203389924))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "sgd = SGD(lr=0.01, momentum=0.9, decay=1e-4, nesterov=True)\n",
        "model.compile(loss='mse',\n",
        "              optimizer=sgd,\n",
        "              metrics=['acc'])\n",
        "callbacks_list = [EarlyStopping(monitor=\"val_loss\", patience=10)]\n",
        "history = model.fit(x_train, y_train, epochs=1000, batch_size=512, validation_data=(x_test, y_test), verbose=0, callbacks=callbacks_list)\n",
        "val_loss, val_acc = model.evaluate(x_test1, y_test1, verbose=0)\n",
        "print('Test accuracy:', val_acc)\n",
        "print('Test loss:', val_loss)\n",
        "print(model.summary())\n",
        "y_pred_proba = model.predict(x_test)\n",
        "#print(y_pred_proba)\n",
        "#y_pred = np.where(y_pred_proba > 0.5, 1, 0)\n",
        "#print(y_pred)\n",
        "#pd.DataFrame(y_pred).to_csv(\"/content/drive/My Drive/Colab Notebooks/data5.csv\")\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}